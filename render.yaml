# Render Blueprint for Backend Deployment
# Deploy: Connect repo to Render and it will auto-detect this file

services:
  # Backend API
  - type: web
    name: linkedin-api
    env: python
    region: singapore
    plan: starter
    buildCommand: "cd backend/api && pip install -r requirements.txt"
    startCommand: "cd backend/api && uvicorn main:app --host 0.0.0.0 --port $PORT"
    envVars:
      - key: SUPABASE_URL
        sync: false
      - key: SUPABASE_KEY
        sync: false
      - key: RABBITMQ_HOST
        value: localhost
      - key: RABBITMQ_PORT
        value: 5672
      - key: RABBITMQ_USER
        value: guest
      - key: RABBITMQ_PASSWORD
        value: guest

  # Scoring Consumer (Background Worker)
  - type: worker
    name: linkedin-scoring
    env: python
    region: singapore
    plan: starter
    buildCommand: "cd backend/scoring && pip install -r requirements.txt"
    startCommand: "cd backend/scoring && python scoring_consumer.py"
    envVars:
      - key: SUPABASE_URL
        sync: false
      - key: SUPABASE_KEY
        sync: false
      - key: RABBITMQ_HOST
        value: localhost
      - key: RABBITMQ_PORT
        value: 5672
      - key: RABBITMQ_USER
        value: guest
      - key: RABBITMQ_PASSWORD
        value: guest
      - key: SCORING_QUEUE
        value: scoring_queue

# NOTE: Crawler CANNOT run on Render because it needs Chrome browser with GUI
# Solution: Run crawler locally or on VPS with display support
# Use: ./start-all.sh start-visible (local)
# Or: Deploy to VPS with Docker and X11 forwarding

# RabbitMQ: Use external service like CloudAMQP or run on separate server
# Free tier: https://www.cloudamqp.com/
